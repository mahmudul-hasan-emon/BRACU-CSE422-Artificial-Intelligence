# -*- coding: utf-8 -*-
"""6_19101098_MahmudulHasanEmon

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1UqLMCeIFGQYdSqTOyCxF9Qj4-tuxlNsL

**Data preprocessing**
"""

import pandas as pd

wine = pd.read_csv("/content/wine.csv")

wine.shape

wine.head() # default = 5

wine.sample() # default = 1

wine.columns

wine.isnull()

wine.isnull().sum()

# Impute missing values-01

#No NaN values found in this "wine dataset" that's why did not handle missing values.

wine.info()

#enconde categorical features
# Encode-01
# built-in class 


from sklearn.preprocessing import LabelEncoder
# Set up the LabelEncoder object
enc = LabelEncoder()

# Apply the encoding to the "Accessible" column
wine['quality_enc'] = enc.fit_transform(wine['quality'])

# Compare the two columns
print(wine[['quality','quality_enc']].head(12))

print(wine["free sulfur dioxide"].max())
print(wine["free sulfur dioxide"].min())

from sklearn.preprocessing import MinMaxScaler

list_of_features = ["free sulfur dioxide"]

scaler = MinMaxScaler()

scaler.fit(wine[list_of_features])

scaled_data = scaler.transform(wine[list_of_features])

print(scaled_data.max())

print(scaled_data.min())

scaled_data

from sklearn.model_selection import train_test_split

list_of_features = ['fixed acidity','volatile acidity','citric acid','residual sugar','chlorides','free sulfur dioxide','total sulfur dioxide','density','pH','sulphates','alcohol']
x_data = wine[list_of_features]
y_data = wine["quality_enc"]

X_train, X_test, y_train, y_test = train_test_split(x_data, y_data,random_state=1)

"""**Assignment-5: Regression**"""

# Import the dependencies for logistic regression
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report
from sklearn.metrics import accuracy_score
from sklearn.model_selection import train_test_split

#Train the model
model = LogisticRegression()
model.fit(X_train, y_train) #Training the model
predictions = model.predict(X_test)
print(predictions)# printing predictions

lr= LogisticRegression()
lr.fit(X_train, y_train)
y_predict_lr= lr.predict(X_test)

from sklearn.metrics import accuracy_score
accuracy_lr= accuracy_score(y_test, y_predict_lr)
accuracy_lr

from sklearn.tree import DecisionTreeClassifier
dtc= DecisionTreeClassifier(criterion='entropy', random_state=1)
dtc.fit(X_train, y_train)
y_predict_dtc=dtc.predict(X_test)

from sklearn.metrics import accuracy_score
accuracy_dtc= accuracy_score(y_test, y_predict_dtc)
accuracy_dtc

import matplotlib.pyplot as plt
plt.figure(figsize=(10,10))
classifiers = ['Logistic Regression', 'Decision Tree']
accuracy= [accuracy_lr, accuracy_dtc]
plt.bar(classifiers, accuracy)
plt.show()